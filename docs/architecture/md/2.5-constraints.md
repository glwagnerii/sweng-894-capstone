## 2.5 Constraints
This table lists the constraints of the Classifi-Cam system.

<div style="display: flex; justify-content: center;"><div style="font-size: 0.9em; max-width:85%; line-height:1.4">

| Constraint | Description                                                                                                                               |
| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| CON-1      | The system shall use the Tauri framework to enable cross-platform deployment on iOS, Android, macOS, Windows, and Linux.                  |
| CON-2      | The system shall be developed using Rust for backend logic to ensure performance and safety.                                              |
| CON-3      | The system shall use Svelte for the frontend to create reactive and efficient user interfaces.                                            |
| CON-4      | The system shall support plugin-based model extensibility, allowing users to install and manage domain-specific classification models.    |
| CON-5      | The system shall be able to operate offline without dependency on backend services or network connectivity.                               |
| CON-6      | The system shall integrate with Google Drive and iCloud Drive for cloud storage access and synchronization.                               |
| CON-7      | The system shall implement security controls to protect user data and ensure privacy.                                                     |
| CON-8      | The system shall provide comprehensive logging and auditing capabilities to track user actions and detect any security-related incidents. |
| CON-9      | The system shall comply with relevant data privacy regulations (e.g., GDPR) to ensure user data protection.                               |
| CON-10     | The system shall use ONNX (Open Neural Network Exchange) for model interoperability.                                                      |
| CON-11     | The system shall use the ORT rust crate library for efficient model execution.                                                            |
| CON-12     | The system shall leverage open-source libraries and components for functionality not directly provided by the core application.           |
| CON-13     | The system shall enforce a maximum size limit of 100MB for AI models to ensure efficient performance and compatibility.                   |
| CON-14     | The system shall use PyTorch as the primary framework for training AI models, ensuring flexibility and scalability in model development.  |
| CON-15     | The system shall support hardware-accelerated AI model inference using CUDA on NVIDIA GPUs and Metal on Apple devices.                    |

</div></div>